{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModel, AutoTokenizer, BertTokenizer, BertForQuestionAnswering\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic QA on covid-19 wikipedia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db6c2e94b3a42cb82367812c6106a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIRECTORY = \"/home/xcs224u_student/notebooks/cs224u/github_repo/data\"\n",
    "nlp_qa = pipeline('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 4987.28it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 3581.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9632967461141817, 'start': 42, 'end': 50, 'answer': 'New-York.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context='Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVID_ARTICLE=\"Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).[8] The disease was first identified in December 2019 in Wuhan, the capital of China's Hubei province, and has since spread globally, resulting in the ongoing 2019–20 coronavirus pandemic.[9][10] Common symptoms include fever, cough and shortness of breath.[5] Other symptoms may include fatigue, muscle pain, diarrhoea, sore throat, loss of smell and abdominal pain.[5][11][12] The time from exposure to onset of symptoms is typically around five days, but may range from two to fourteen days.[5][13] While the majority of cases result in mild symptoms, some progress to viral pneumonia and multi-organ failure.[9][14] As of 10 April 2020, more than 1.67 million[7] cases have been reported in more than 200 countries and territories,[15] resulting in more than 101,000 deaths.[7] More than 372,000 people have recovered. The virus is mainly spread between people during close contact,[a] often via small droplets produced during coughing,[b] sneezing, or talking.[6][16][18] While these droplets are produced when breathing out, they usually fall to the ground or surfaces rather than being infectious over large distances.[6][19][20] People may also become infected by touching a contaminated surface and then their face.[6][16] The virus can survive on surfaces for up to 72 hours.[21] Coronavirus is most contagious during the first three days after onset of symptoms, although spread may be possible before symptoms appear and in later stages of the disease.The standard method of diagnosis is by real-time reverse transcription polymerase chain reaction (rRT-PCR) from a nasopharyngeal swab.[23] The infection can also be diagnosed from a combination of symptoms, risk factors and a chest CT scan showing features of pneumonia.Recommended measures to prevent infection include frequent hand washing, maintaining physical distance from others (especially from those with symptoms), covering coughs and sneezes with a tissue or inner elbow and keeping unwashed hands away from the face.[26][27] The use of masks is recommended for those who suspect they have the virus and their caregivers.[28] Recommendations for mask use by the general public vary, with some authorities recommending against their use, some recommending their use and others requiring their use.[29][30][31] Currently, there is no vaccine or specific antiviral treatment for COVID-19.[6] Management involves treatment of symptoms, supportive care, isolation and experimental measures.The World Health Organization (WHO) declared the 2019–20 coronavirus outbreak a Public Health Emergency of International Concern (PHEIC)[33][34] on 30 January 2020 and a pandemic on 11 March 2020.[10] Local transmission of the disease has been recorded in many countries across all six WHO regions.[35]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 25.72it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.30009528747927305,\n",
       " 'start': 189,\n",
       " 'end': 234,\n",
       " 'answer': \"Wuhan, the capital of China's Hubei province,\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=CONVID_ARTICLE, question='Where is based Hugging Face ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 26.48it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.25412974718281767,\n",
       " 'start': 39,\n",
       " 'end': 104,\n",
       " 'answer': 'an infectious disease caused by severe acute respiratory syndrome'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=CONVID_ARTICLE, question='What is covid-19 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 25.78it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 8981.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.23947629162223372,\n",
       " 'start': 352,\n",
       " 'end': 392,\n",
       " 'answer': 'fever, cough and shortness of breath.[5]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_qa(context=CONVID_ARTICLE, question='What are the symptoms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get baseline model working squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can pass file paths to from_pretrained to load pretained weights, not sure what dataset they used to train these, I think SQUAD V1\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 27227, 2001, 1037, 3835, 13997, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "tensor([[-4.0490, -4.1443, -5.7222, -2.4875, -5.2655, -8.2328, -4.0487,  0.3495,\n",
      "         -3.8018, -1.2565,  7.1202,  5.9041,  3.4469, -4.0490]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[ 1.1705, -4.7681, -5.0704, -4.3949, -1.5484, -4.6083,  1.1709, -3.3678,\n",
      "         -0.8850, -3.4272, -0.7656,  2.3183,  7.1591,  1.1703]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'nice', 'puppet', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "input_ids = tokenizer.encode(question, text) # add deimiter tokens, return vocab index\n",
    "\n",
    "token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))] #\n",
    "\n",
    "#Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]: 0 corresponds to a sentence A token,\n",
    "#1 corresponds to a sentence B token\n",
    "\n",
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(input_ids)\n",
    "print(token_type_ids)\n",
    "print(start_scores)\n",
    "print(end_scores)\n",
    "print(all_tokens)\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "\n",
    "assert answer == \"a nice puppet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline model  SQUAD using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fab211f3deb4619a9d0fc8f1c18af7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "# Question answering pipeline, specifying the checkpoint identifier\n",
    "qa_squad_pipeline = pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 78.21it/s]\n",
      "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9680584762547824, 'start': 52, 'end': 60, 'answer': 'New-York.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_squad_pipeline(context='i love u, Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate the model on squad 2.0: Generate evaluation JSON from dev set and and feed it to evaluate-v2.0.py to obtain metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers.data.processors import squad\n",
    "processor = squad.SquadV2Processor()\n",
    "dev_squad_2 = processor.get_dev_examples(DATA_DIRECTORY, \"squad/dev-v2.0.json\")\n",
    "#squad datasets: https://rajpurkar.github.io/SQuAD-explorer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_evaluation_squad_json(squadExamples, predictions, filename=DATA_DIRECTORY+'/evaluation.json'):\n",
    "    obj = {};\n",
    "    index =0\n",
    "    for example in squadExamples:\n",
    "        obj[example.qas_id] = predictions[index][\"answer\"]\n",
    "        index += 1;\n",
    "    with open(filename, 'w') as fout:\n",
    "        json.dump(obj, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation file doesnt exist, creating it\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "SQUAD2_BASIC_EVALUATION_FILENAME = \"/squad/evaluation_dev_basic_squad1.json\"\n",
    "if os.path.isfile(DATA_DIRECTORY+SQUAD2_BASIC_EVALUATION_FILENAME) == False:\n",
    "    print(\"evaluation file doesnt exist, creating it\")\n",
    "    qa_squad_predictions = qa_squad_pipeline(dev_squad_2)\n",
    "    save_evaluation_squad_json(dev_squad_2, qa_squad_predictions, DATA_DIRECTORY+SQUAD2_BASIC_EVALUATION_FILENAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics obtained squad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "SCRIPT_PATH = DATA_DIRECTORY+\"/evaluate-v2.0.py\"\n",
    "DEV_V2_PATH = DATA_DIRECTORY + \"/squad/dev-v2.0.json\"\n",
    "EVALUATION_DEV_BASIC_PATH = DATA_DIRECTORY + SQUAD2_BASIC_EVALUATION_FILENAME\n",
    "print(os.system(\"python \" + SCRIPT_PATH + \" \" + DEV_V2_PATH + \" \" + EVALUATION_DEV_BASIC_PATH))\n",
    "# fixme: need to run this on shell manually and copy results, cause this doesn't get console output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 39.15606839046576,\n",
       " 'f1': 43.14232380992385,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 78.42442645074225,\n",
       " 'HasAns_f1': 86.40836885884374,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 0.0,\n",
       " 'NoAns_f1': 0.0,\n",
       " 'NoAns_total': 5945}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#python evaluate-v2.0.py squad/dev-v2.0.json squad/evaluation_dev_basic.json\n",
    "\n",
    "{\n",
    "  \"exact\": 39.15606839046576,\n",
    "  \"f1\": 43.14232380992385,\n",
    "  \"total\": 11873,\n",
    "  \"HasAns_exact\": 78.42442645074225,\n",
    "  \"HasAns_f1\": 86.40836885884374,\n",
    "  \"HasAns_total\": 5928,\n",
    "  \"NoAns_exact\": 0.0,\n",
    "  \"NoAns_f1\": 0.0,\n",
    "  \"NoAns_total\": 5945\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT was finetuned on SQUAD V1 so it fails to predict no-answers, grab some examples to ilustrate this. how can I get it to predict no-answers? need it for baseline, checkout this paper: https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15759479.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on squad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os;\n",
    "#dev_squad_2 = processor.get_dev_examples(DATA_DIRECTORY, \"squad/dev-v1.0.json\")\n",
    "\n",
    "#SQUAD1_BASIC_EVALUATION_FILENAME = \"/squad/evaluation_dev_basic_squad1.json\"\n",
    "#if os.path.isfile(DATA_DIRECTORY+SQUAD1_BASIC_EVALUATION_FILENAME) == False:\n",
    " #   print(\"evaluation file doesnt exist, creating it\")\n",
    "  #  qa_squad1_predictions = qa_squad_pipeline(dev_squad_1)\n",
    "   # save_evaluation_squad_json(dev_squad_1, qa_squad1_predictions, DATA_DIRECTORY+SQUAD1_BASIC_EVALUATION_FILENAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model using BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
